fggarra---
title: "Clustering Techniques"
author: "Teresa Del Bianco"
output:
  html_document:
    df_print: paged
---

```{r}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

# Generate data

Let's generate 2000 random points with normal distribution. Each point is randomly assigned to one of 6 attractors rcl. 

```{r}
set.seed(0)
d <- data.frame(x=(rnorm(n = 2000)), y=rnorm(n=2000), rcl=factor(sample(1:6, 2000, replace=TRUE)))
head(d)
```
```{r}
library(ggplot2)
ggplot(data=d, aes(x=x, y=y, col=rcl)) + geom_point()
```

## Generate random attractors

The attractors are 6 points randomly assigned to x and y coordinates. 

```{r}
rp <- data.frame(x.c=abs(rnorm(1:6, sd=4)), 
                 y.c=abs(rnorm(6, sd=4)), 
                 rcl=factor(sample(1:6, replace=FALSE)))
ggplot(data=rp, 
       aes(x=x.c, y=y.c, col=rcl)) + 
  geom_point()
```

## Plot the fake gaze data

We cluster the random data points by dragging it to the predefined attractors. 

```{r}
library(dplyr)
dc <- d %>%
  left_join(rp, by="rcl") %>%
  mutate(x.n=x+(x.c),
         y.n=y+(y.c)) %>%
  dplyr::select(rcl, x.n, y.n)
dc
ggplot(data=dc, aes(x=x.n, y=y.n, col=rcl)) + geom_point()
```

And we remove the label:

```{r}
ggplot(data=dc, aes(x=x.n, y=y.n)) + 
  geom_point(shape=21) + 
  labs(title="??") + 
  theme(plot.title = element_text(hjust = 0.5))
```

Let's report the fake gaze data to a picture. 

```{r}
library(grid)
image <- jpeg::readJPEG("Henry_Meynell_Rheam_-_Sleeping_Beauty copy.jpg")
ggplot(data=dc, aes(x=x.n, y=y.n)) + labs(title="??") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  annotation_custom(rasterGrob(image, width = unit(1,"npc"), height = unit(1,"npc")), -Inf, Inf, -Inf, Inf) + 
  geom_point(shape=21, size=2, col="white") + coord_fixed()
```

# K-means Clustering Method

K-means is an unsupervised classification method. The algorthms creates clusters with minimum internal variance measured as the within-cluster sum of squares. The algorithm iteratively assigns each data point to the cluster whose mean has the least squared ("nearest") mean, and calculates the mean of the updated cluster (the centroid). The algorithm converges when the assiment of the data points does not change anymore by updating the cluster mean. 

## The Elbow Test

This test calculates a measure of the error estimate (the Sum of Squared Error) for a predefined number of clusters (up to 10). Since increasing the clusters indefinively reduces the SSE to 0, we are looking for the number of clusters that gives the minimum SSE before saturation. 

```{r}
# Determine number of clusters
dc.b <- dc[,-1]
dc.b
wss <- (nrow(dc.b)-1)*sum(apply(dc.b,2,var))

for (i in 2:10) wss[i] <- sum(kmeans(dc.b, 
   centers=i)$withinss)

library(ggplot2)
ggplot(data=data.frame(Clusters=as.factor(10:1),
                       SEE=sort(wss, decreasing = FALSE),
                       group=1),
       aes(x=Clusters, y=SEE, group=group)) +
  geom_point() +
  geom_line()
```

We select 3 clusters for the following steps. 

```{r}
# K-Means Cluster Analysis
fit <- kmeans(dc.b, 3) # 3 cluster solution
# get cluster means 
aggregate(dc.b,by=list(fit$cluster),FUN=mean)
# append cluster assignment
cl.d <- data.frame(dc.b, fit$cluster)
head(cl.d)
```

```{r}
ggplot(data=cl.d, aes(x=x.n, y=y.n)) + labs(title="K-means", fill="Cluster") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  annotation_custom(rasterGrob(image, width = unit(1,"npc"), height = unit(1,"npc")), -Inf, Inf, -Inf, Inf) + 
  geom_point(shape=21, size=2, col="white", alpha=0.5, aes(fill=factor(fit.cluster))) + 
  coord_fixed() 
```

# K-Medoids

The method "Partitioning around medoids" selects a k number of medoids or cluster centers. The closest points are assigned to one cluster or another and the sum of the distance of a data point from the cluster centre is calculated. The operation is re-iterated by swapping the medoids, calculating the sum of distance and subtracting it from the previous distance estimate. If difference > 0, the swap is reverted. The algorithm converges when the difference equals 0. 

```{r}
library(fpc)
library(cluster)
pamk.best <- pamk(dc.b)
med <- pamk.best$pamobject$medoids
cl.pam <- data.frame(dc.b, pam.cluster=pamk.best$pamobject$clustering)
head(cl.pam)
```

```{r}
ggplot(data=cl.pam, aes(x=x.n, y=y.n)) + 
  labs(title="Partitioning Around Medoids",
       fill="Cluster",
       caption="X = Medoid") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  annotation_custom(rasterGrob(image, width = unit(1,"npc"), height = unit(1,"npc")), -Inf, Inf, -Inf, Inf) + 
  geom_point(shape=21, size=2, col="white", alpha=0.5, aes(fill=factor(pam.cluster))) + 
  coord_fixed() +
  geom_point(data=as.data.frame(med), aes(x=x.n, y=y.n), shape="X", col="red", size=4) +
  theme(plot.caption = element_text(hjust = 0.5, colour = "red"))
```

# Mean Shift Clustering

This method places a weight function (or kernel) under each data point to built a probability distribution. The distribution will change depending on the bandwidth chosen. The algorithm shifts the data points onto the closest peak of the probability distrubution until any point cannot be shifted any longer. The bandwidth has a smoothing effect on the surface of the probability distribution. 

```{r}
library(MASS)
# scale data by their range
# ma <- cbind(ma.x.n=max(dc.b$x.n), ma.y.n=max(dc.b$y.n))
# mi <- cbind(mi.x.n=min(dc.b$x.n), mi.y.n=min(dc.b$y.n))
# ra <- ma-mi
# sc <- dc.b/ra

# scale data by sd
sd <- cbind(x.n=sd(dc.b$x.n), y.n=sd(dc.b$y.n))

sc.d <- dc.b/sd

#estimate bandwidth
# bandwidth.nrd(sc.d$x.n)
# bandwidth.nrd(sc.d$y.n)

#calculate density
z <- kde2d(sc.d$x.n, sc.d$y.n)

#plot density map
pic <- ggplot(sc.d, aes(x=x.n, y=y.n)) +
  annotation_custom(rasterGrob(image, width = unit(1,"npc"), height = unit(1,"npc")), -Inf, Inf, -Inf, Inf) + 
  stat_density2d(aes(fill=..level..), geom="polygon", alpha=0.5, h=c(0.3, 0.3)) +
  stat_density2d(aes(col=..level..), h=c(0.3, 0.3)) +
  scale_fill_gradient2(low="skyblue2", high="firebrick1", midpoint=mean(range(z$z))) +
  scale_color_continuous(low="skyblue2", high="firebrick1") +
  coord_fixed() +
  labs(y="") +
  guides(color=FALSE)

points <- ggplot() +
  geom_point(data=sc.d, aes(x=x.n, y=y.n),
    shape=21, size=2, col="black", fill="gray", alpha=0.8, size=2) + 
  stat_density2d(data=sc.d, aes(x=x.n, y=y.n, fill=..level..), geom="polygon", alpha=0.5, h=c(0.3, 0.3)) +
  stat_density2d(data=sc.d, aes(x=x.n, y=y.n, col=..level..), h=c(0.3, 0.3)) +
  scale_fill_gradient2(low="skyblue2", high="firebrick1", midpoint=mean(range(z$z))) +
  scale_color_continuous(low="skyblue2", high="firebrick1") +
  coord_fixed() +
  labs(y="") +
  guides(color=FALSE)
  

library(ggpubr)
twop1 <- ggarrange(pic, points, ncol = 2, common.legend = TRUE, legend = "right")
twop1 <- annotate_figure(twop1,
               top = text_grob("Multivariate kernel density estimation"),
               bottom = text_grob("Scaling: SD \n Bandwidth: 0.3",
                                  hjust = 1),
               left = text_grob("y.n", rot = 90))
# ggsave(plot = twop1, filename = "twop1-2.pdf")
twop1
```

```{r}
# install.packages("LPCM")
set.seed(88)
library(LPCM)
cl.ms <- ms(as.matrix(sc.d), scaled=0, h=0.3) 
plot(cl.ms)
cl.ms$h
cl.ms$cluster.center
```

```{r}
sc.d$shift.cluster <- cl.ms$cluster.label
```

```{r}
x <- cbind(cl.ms$cluster.center[,1])
rownames(x) <- NULL
y <- cbind(cl.ms$cluster.center[,2])
rownames(y) <- NULL
cc <- cbind(1:nrow(x))
coo <- as.data.frame(cbind(x,y,cc))
colnames(coo) <- c("x.n", "y.n", "cc")

# cc <- data.frame(x=c(0.79, 2.41, 1.98, 1.60, 2.08, 2.08, 3.20), 
#                                  y=c(0.62, 0.76, 0.04, 3.02, 1.45, 0.65, 4.18), 
#                                  cc=as.factor(c(1,2,3,4,5,6,7))) #I hardcoded this because it wouldnt knit it otherwise...

modes <- points + geom_point(aes(x=x.n, 
                                 y=y.n, 
                                 shape=as.factor(cc)), 
                             data=coo,
                             fill="blue", size=4) + 
  labs(col="Shift Cluster") + 
  scale_shape_manual(values = c(21,22,23,24)) +
  labs(shape="Cluster Center")
modes
```

```{r}
sc.d.1 <- subset(sc.d, shift.cluster==1)
sc.d.2 <- subset(sc.d, shift.cluster==2)
sc.d.3 <- subset(sc.d, shift.cluster==3)
sc.d.4 <- subset(sc.d, shift.cluster==4)
# sc.d.5 <- subset(sc.d, shift.cluster==5)
# sc.d.6 <- subset(sc.d, shift.cluster==6)
# sc.d.7 <- subset(sc.d, shift.cluster==7)

library(ggalt)
cl <- ggplot(data=sc.d, aes(x=x.n, y=y.n)) + 
  labs(y="") + 
  annotation_custom(rasterGrob(image, width = unit(1,"npc"), 
                               height = unit(1,"npc")), -Inf, Inf, 
                    -Inf, Inf) + 
  geom_point(size=4,
             aes(shape=factor(shift.cluster)),
             alpha=0.5) + 
  coord_fixed() +  
  scale_shape_manual(values = c(21,22,23,24
                                )) +
  labs(shape="Cluster Center") +
  geom_point(aes(x=x.n, y=y.n, shape=as.factor(cc)), fill="blue", data=coo, size=4) + 
  geom_encircle(data = sc.d.1, col="red", linetype="twodash") + 
  geom_encircle(data = sc.d.2, col="red", linetype="longdash") + 
  geom_encircle(data = sc.d.3, col="red", linetype="dotdash") + 
  geom_encircle(data = sc.d.4, col="red", linetype="solid") 
# + 
  # geom_encircle(data = sc.d.5, col="red", linetype="F1") + 
  # geom_encircle(data = sc.d.6, col="red", linetype="dotted") + 
  # geom_encircle(data = sc.d.7, col="red", linetype="dashed") 
twop2 <- ggarrange(cl, modes, ncol = 2, common.legend = TRUE, legend = "right")
twop2 <- annotate_figure(twop2,
               top = text_grob("Mean Shift Clustering"),
               bottom = text_grob("Scaling: SD \n Bandwidth: 0.3",
                                  hjust = 1),
               left = text_grob("y.n", rot = 90))
# ggsave(plot = twop2, filename ="twop2.pdf", width = 10)
twop2
```

