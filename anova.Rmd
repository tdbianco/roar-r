---
title: "ANOVA - Analysis of Variance"
---
This is based on my notes of the statistics course given by Prof. Brian Dillon (UMass Amherst).

# Anova

Anova is the analysis of variance based on differences among means of more than two samples, by comparing two estimates of population variance. The first estimate comes from the average of the variance on each group, the within-group or residual variance; the residual variance is determined by chance factors, usually unknown, that influence each observation unpredictably. The second type of variance comes from the variation of means of the samples, the between-group estimate of variance, that varies systematically with our factors of interest, such as treatment or condition.

## T-test is a special case of Anova, and Anova is a special case of Linear Regression

When only two groups are compared, the T-test and the Anova hold the same result. Both examine if the population means differ from one another, assuming equal variances for both. The same assumption extends to linear regression, where the residuals (data with group means subtracted) have to be equivalent. In R, the fuction 'aov' is actually a wrapper of 'lm'! 

# An example with the Variances

Let's create a dummy dataset:

```{r}
group <- c(rep(1, 10), rep(2, 10), rep(3, 10)) #idv
response <- round(rnorm(30, mean = 80, sd = 12), digits = 2) #dv
df <- cbind(group, response) #ds
df<-data.frame(df) #various steps to format the ds
names(df)<-c("treatment", "score")
df$treatment<-as.factor(df$treatment)
head(df)
```

Let's calculate the variances

```{r}
# Root mean squared error for each group
av.sqrt1<-mean(sqrt1<- with(df, sqrt(score[treatment==1])))

av.sqrt2<-mean(sqrt2<- with(df, sqrt(score[treatment==2])))

av.sqrt3<-mean(sqrt3<- with(df, sqrt(score[treatment==3])))

# Group Means
m1<-with(df, mean(score[treatment==1]))
m2<-with(df, mean(score[treatment==2]))
m3<-with(df, mean(score[treatment==3]))

# Grand Mean
GM<-(m1+m2+m3)/3

#Variance Within
Vwith<-(av.sqrt1+av.sqrt2+av.sqrt3)/3

#Variance Between
Vbet<-((m1-GM)^2)+((m2-GM)^2)+((m3-GM)^2)/2

cat("Within Group Variance:", round(Vwith, 2), "\n")
cat("Between Group Variance:", round(Vbet, 2))
```

Within the groups, observations vary by a factor of `r Vwith` on average, due to chance factors, such as unsystematic measurement error, idiosynchratic differences between participants and other unknown factors. The average variance between the groups is `r Vbet`: the statistical test will investigate if this variance is attributable to treatment - a factor that systematically varies between the groups. 

# Running the ANOVA

Output of the test: 

```{r}
aov<-aov(score~treatment, df)
s.aov<-summary(aov) 
s.aov
```

Means per group (that we calculated manually before), and coefficients of the treatment effect (unstandardised effect size), with standard error:

```{r}
model.tables(aov, "mean", se=TRUE) #means
```

```{r}
model.tables(aov, "effects", se=TRUE) #coefficients
```

Let's format the output a bit:

```{r}
library(broom)
tidy.summ<-tidy(aov)
tidy.summ
```


## Reporting

The treatment effect `r ifelse(tidy.summ$p.value[1]<0.05, "gave", "did not give")` a statistically significant difference, with `r paste0("F(", tidy.summ$df[1], ",", tidy.summ$df[2], ") = ", ifelse(round(tidy.summ$statistic[1], 2)==0, "< 0.001", round(tidy.summ$statistic[1], 2)), ", p-value = ", ifelse(tidy.summ$p.value[1]<0.001, paste0("p-value < 0.001"), round(tidy.summ$p.value[1], 2)))`

# Effect Size

After computing ANOVA, you may calculate the Effect Size, R-Squared, that tells you how much of the variance is due to the treatment effect:

```{r}
sum_squares_treatment <- tidy.summ$sumsq[1]
sum_squares_residuals <- tidy.summ$sumsq[2]

R_squared <- sum_squares_treatment /
            (sum_squares_treatment + sum_squares_residuals)

R_squared
```

The effects size R-Squared is `r paste0(round(R_squared, 2))`. 

# Factorial Anova

In a factorial analysis of variance there are two groups (in the below example, type A and B), and a measure that has been acquired in a between subject design. In this case, each subject in each group underwent a different test (y or z). 

Therefore, in our anova, we are going to consider the main effect of group, the main effect of test and the interaction between the two. 

```{r}
subj1<-rep(1:30)
group1<-rep("a", 30)
condition<-rep(c("y", "z"), 15)
response1<-round(rnorm(30, mean = 15, sd = 0.5), digits = 2)

subj2<-rep(31:60)
group2<-rep("b", 30)
response2<-round(rnorm(30, mean = 18, sd = 0.7), digits = 2)

fa_1<-cbind(subj1, group1, condition, response1)
fa_2<-cbind(subj2, group2, condition, response2)
fa<-rbind(fa_1, fa_2)
fa.df<-as.data.frame(fa)
colnames(fa.df)<-c("subj", "group", "test", "response")
fa.df$response<-as.character(fa.df$response)
fa.df$response<-as.numeric(fa.df$response)
str(fa.df)
```

Output:

```{r}
av<-aov(response ~ group*test, fa.df)
tidy.summ<-tidy(av)

```

And effects sizes:

```{r}
ssq<-tidy.summ$sumsq
dof<-tidy.summ$df
dof_res<-tidy.summ$df[4]

ES1<-(ssq[1]*dof[1])/(ssq[1]+dof[1]+dof_res)
ES2<-(ssq[2]*dof[2])/(ssq[2]+dof[2]+dof_res)
ES3<-(ssq[3]*dof[3])/(ssq[3]+dof[3]+dof_res)

cat("ES of group:", ifelse(ES1<0.001, "< 0.001", round(ES1, 2)), "\n")
cat("ES of test:", ifelse(ES2<0.009, "< 0.001", round(ES2, 2)), "\n")
cat("ES of interaction:", ifelse(ES3<0.009, "< 0.001", round(ES3, 2)), "\n")
```

# Repeated measures ANOVA

One of the assumptions of ANOVA is that the groups of which we are examining the means are independent. In other words, they do not have to be correlated, as it happens when you measure the same things on the same group of individuals. Broadly speaking, the errors will be smaller because measurements come from the same people, and this could significantly misallign your result. Look at our residual in the previous ANOVA: it's approximately `r round(ssq[4])` but it might be bigger if we didn't account for the correlation! 
The approach of ANOVA to this problem is to separate the calculations depending on different "strata", and run a separate linear regression for each of them. In the formula, we need to specify the strata, for example, 1 for each subject. Note: while this is similar to a mixed model, it is *NOT a mixed model*. A mixed model does not run a separate least-square regression for each strata, but rather allow a different estimate of each coefficient within a pre-defined nesting. 

In this example, each participant of group A and B made the two measurements of tests y and z. So we have two scores for each subject (within-subject design).  

```{r}
subjr<-rep(1:30,2)
subjr<-sort(subjr)
groupr<-rep(c("a", "a", "b", "b"), 15)
testr<-rep(c("y", "z"), 15)
responser<-sample(round(rnorm(500, mean=8, sd=6), digits=3), 60)
rd.df<-as.data.frame(cbind(subjr, groupr, testr, responser))
rd.df$responser<-as.numeric(as.character(rd.df$responser))
summary(rd.df)
```

```{r}
r.av<-aov(responser ~ groupr*testr + Error(subjr), data = rd.df)
summ.tidy.rr<-tidy(r.av)
summ.tidy.rr.eff<-subset(summ.tidy.rr, term!="Residuals")
summ.tidy.rr.res<-subset(summ.tidy.rr, term=="Residuals", select = -c(statistic, p.value))
```

Here are the statistics of the effects. We have three estimates, just as before, 2 for the effects of group and test, and their reciprocal interaction. The "stratum" indicates the grouping  - in this case overall and repeated within subject. First, the between-subject factor is listed (group), and then the within-subject factors (test and its interaction):

```{r}
summ.tidy.rr.eff
```

In fact, we have two residual errors this time, the between and the within subject errors:

```{r}
summ.tidy.rr.res
```

We can calculate the percentage of variance explained by group, excluding the within-subject variation (partial ETA-Squared):

```{r}
p.eta.group<-summ.tidy.rr.eff$sumsq[1]/(summ.tidy.rr.eff$sumsq[1]+summ.tidy.rr.res$sumsq[1])
cat("Partial Eta-Squared (group):", round(p.eta.group, 2))
```

The total eta-squared uses the total sum of squares, including both between and within subject errors:

```{r}
eta.group<-summ.tidy.rr.eff$sumsq[1]/(summ.tidy.rr.eff$sumsq[1]+summ.tidy.rr.res$sumsq[1]+summ.tidy.rr.res$sumsq[2])
cat("Eta-Squared (group):", round(eta.group, 2))
```

In summary, the approach of repeated-measures anova to repeated measures is *separation*, ie, fitting strata-level regressions per each unit of repetition. This works well when the groups are balanced, ie, each subject has equal number of observations and, hence, degrees of freedom, on which the calculation of the sum of squares is based. But if a subject misses one observations, it needs to be dropped or imputed. When the groups are unbalanced and we don't want to drop subjects or impute observations, we need to take another approach. One is to use a linear model adding a correlation term between observations, "relaxing" the assumption of independence (Marginal Model or GEE). Another approach is to introduce another kind of effect, the random effect, typical of the mixed model, that allow to extract individual-level estimates. 